{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/train_cleaned_v0.0.csv')\n",
    "test = pd.read_csv('./Data/test_cleaned_v0.0.csv')\n",
    "train_raw = pd.read_csv('./Data/training_set_values.csv')\n",
    "test_raw = pd.read_csv('./Data/test_set_values.csv')\n",
    "\n",
    "#train = train.merge(train_raw[['id','extraction_type_group','extraction_type_class','payment','quality_group','source_class','source_type','waterpoint_type_group','management_group','quantity_group','wpt_name']],on='id')\n",
    "#test = test.merge(test_raw[['id','extraction_type_group','extraction_type_class','payment','quality_group','source_class','source_type','waterpoint_type_group','management_group','quantity_group','wpt_name']],on='id')\n",
    "\n",
    "labels = pd.read_csv('./Data/training_set_labels.csv')\n",
    "train = train.merge(labels, on=\"id\")\n",
    "target = train.pop(\"status_group\")\n",
    "\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "\n",
    "data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded', 'latitude','longitude','amount_tsh', 'gps_height', 'population', 'operation_years', 'construction_year']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population_imp_random_choice', 'construction_year_imp_normal', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh_imp_random_choice', 'longitude_imp_normal',\n",
    "                 'longitude_imp_random_choice', 'latitude_imp_normal', 'latitude_imp_random_choice',\n",
    "                 'operation_years_imp_normal', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random sample from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_normal','longitude_imp_normal','amount_tsh_imp_normal',\n",
    "                'gps_height_imp_normal', 'population_imp_normal', 'operation_years_imp_normal',\n",
    "               'construction_year_imp_normal']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height', 'population',\n",
    "               'population_imp_random_choice', 'construction_year', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh', 'amount_tsh_imp_random_choice', 'longitude',\n",
    "                 'longitude_imp_random_choice', 'latitude', 'latitude_imp_random_choice',\n",
    "                 'operation_years', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random choice from empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_random_choice','longitude_imp_random_choice','amount_tsh_imp_random_choice',\n",
    "                'gps_height_imp_random_choice', 'population_imp_random_choice',\n",
    "                'operation_years_imp_random_choice', 'construction_year_imp_random_choice']\n",
    "\n",
    "data = data.drop(['gps_height', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population', 'construction_year_imp_normal', 'construction_year',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh', 'longitude_imp_normal',\n",
    "                 'longitude', 'latitude_imp_normal', 'latitude',\n",
    "                 'operation_years_imp_normal', 'operation_years'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[num_features])\n",
    "data[num_features] = scaler.transform(data[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical features for OneHotEncoding\n",
    "cat_features = list(data.columns)\n",
    "for feature in num_features:\n",
    "    cat_features.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove factorized categorical features\n",
    "regex = re.compile(r'_x')\n",
    "\n",
    "fact_cat = filter(lambda i: regex.search(i), cat_features)\n",
    "fact_cat = [i for i in fact_cat if regex.search(i)]\n",
    "\n",
    "cat_features = filter(lambda i: not regex.search(i), cat_features)\n",
    "cat_features = [i for i in cat_features if not regex.search(i)]\n",
    "\n",
    "data = data.drop(fact_cat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove train and id column for OneHotEncoding\n",
    "cat_features.remove('train')\n",
    "cat_features.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimension of some categorical features\n",
    "dim_red_features = 'funder installer scheme_name lga ward subvillage wpt_name'.split()\n",
    "for feature in dim_red_features:\n",
    "    train = train.assign(count = train.groupby(feature)[feature].transform('count')).sort_values(by = ['count',feature], ascending = [False,True])\n",
    "    top_values = train.drop_duplicates('count')\n",
    "    top_values = list(top_values.nlargest(10, 'count')[feature])\n",
    "    data[feature] = data[feature].apply(lambda x: x if (x in top_values) | (str(x) == 'nan') else 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.concat([data, pd.get_dummies(data[cat_features], dummy_na=True)], axis=1)\n",
    "data = data.drop(cat_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# extract training/test sets\n",
    "train_df = data[data[\"train\"] == 1]\n",
    "test_df = data[data[\"train\"] == 0]\n",
    "train_df.drop([\"train\"], axis=1, inplace=True)\n",
    "train_df.drop(['id'],axis=1, inplace=True)\n",
    "test_df.drop([\"train\"], axis=1, inplace=True)\n",
    "\n",
    "id_test = test_df['id']\n",
    "test_df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(test_df)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions['id'] = id_test\n",
    "predictions.columns = ['status_group','id']\n",
    "predictions = predictions[['id','status_group']]\n",
    "# convert into submission format\n",
    "\n",
    "formatsub = pd.read_csv('./Data/submission_format.csv')\n",
    "submission_format = pd.merge(formatsub, predictions, on=['id'], how='inner')\n",
    "submission_format.drop(['status_group_x'],axis=1,inplace=True)\n",
    "submission_format.columns = ['id','status_group']\n",
    "\n",
    "submission_format.to_csv('./Results/submission_format_SVM_empirical.csv', index=False)\n",
    "submission_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
