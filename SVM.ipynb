{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/train_cleaned_v0.0.csv')\n",
    "test = pd.read_csv('./Data/test_cleaned_v0.0.csv')\n",
    "train_raw = pd.read_csv('./Data/training_set_values.csv')\n",
    "test_raw = pd.read_csv('./Data/test_set_values.csv')\n",
    "\n",
    "labels = pd.read_csv('./Data/training_set_labels.csv')\n",
    "train = train.merge(labels, on=\"id\")\n",
    "target = train.pop(\"status_group\")\n",
    "\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "\n",
    "data = pd.concat([train,test])\n",
    "\n",
    "data['date_recorded'] = pd.to_datetime(data['date_recorded'])\n",
    "data['date_recorded'] = data['date_recorded'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded', 'latitude','longitude','amount_tsh', 'gps_height', 'population', 'operation_years', 'construction_year']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population_imp_random_choice', 'construction_year_imp_normal', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh_imp_random_choice', 'longitude_imp_normal',\n",
    "                 'longitude_imp_random_choice', 'latitude_imp_normal', 'latitude_imp_random_choice',\n",
    "                 'operation_years_imp_normal', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random sample from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_normal','longitude_imp_normal','amount_tsh_imp_normal',\n",
    "                'gps_height_imp_normal', 'population_imp_normal', 'operation_years_imp_normal',\n",
    "               'construction_year_imp_normal']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height', 'population',\n",
    "               'population_imp_random_choice', 'construction_year', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh', 'amount_tsh_imp_random_choice', 'longitude',\n",
    "                 'longitude_imp_random_choice', 'latitude', 'latitude_imp_random_choice',\n",
    "                 'operation_years', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random choice from empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_random_choice','longitude_imp_random_choice','amount_tsh_imp_random_choice',\n",
    "                'gps_height_imp_random_choice', 'population_imp_random_choice',\n",
    "                'operation_years_imp_random_choice', 'construction_year_imp_random_choice']\n",
    "\n",
    "data = data.drop(['gps_height', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population', 'construction_year_imp_normal', 'construction_year',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh', 'longitude_imp_normal',\n",
    "                 'longitude', 'latitude_imp_normal', 'latitude',\n",
    "                 'operation_years_imp_normal', 'operation_years'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[num_features])\n",
    "data[num_features] = scaler.transform(data[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical features for OneHotEncoding\n",
    "cat_features = list(data.columns)\n",
    "for feature in num_features:\n",
    "    cat_features.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove train and id column for OneHotEncoding\n",
    "cat_features.remove('train')\n",
    "cat_features.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimension of some categorical features\n",
    "dim_red_features = 'funder installer scheme_name lga ward subvillage wpt_name'.split()\n",
    "for feature in dim_red_features:\n",
    "    train = train.assign(count = train.groupby(feature)[feature].transform('count')).sort_values(by = ['count',feature], ascending = [False,True])\n",
    "    top_values = train.drop_duplicates('count')\n",
    "    top_values = list(top_values.nlargest(10, 'count')[feature])\n",
    "    data[feature] = data[feature].apply(lambda x: x if (x in top_values) | (str(x) == 'nan') else 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert factorized categorical features to strings\n",
    "data[cat_features] = data[cat_features].applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding of categorical features\n",
    "data = pd.concat([data, pd.get_dummies(data[cat_features], dummy_na=True)], axis=1)\n",
    "data = data.drop(cat_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# extract training/test sets\n",
    "train_df = data[data[\"train\"] == 1]\n",
    "test_df = data[data[\"train\"] == 0]\n",
    "train_df.drop([\"train\"], axis=1, inplace=True)\n",
    "train_df.drop(['id'],axis=1, inplace=True)\n",
    "test_df.drop([\"train\"], axis=1, inplace=True)\n",
    "\n",
    "id_test = test_df['id']\n",
    "test_df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='rbf', max_iter=-1, probability=False, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785  non functional\n",
       "1  51630      functional\n",
       "2  17168  non functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = svm.predict(test_df)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions['id'] = id_test\n",
    "predictions.columns = ['status_group','id']\n",
    "predictions = predictions[['id','status_group']]\n",
    "# convert into submission format\n",
    "\n",
    "formatsub = pd.read_csv('./Data/submission_format.csv')\n",
    "submission_format = pd.merge(formatsub, predictions, on=['id'], how='inner')\n",
    "submission_format.drop(['status_group_x'],axis=1,inplace=True)\n",
    "submission_format.columns = ['id','status_group']\n",
    "\n",
    "submission_format.to_csv('./Results/submission_format_SVM_empirical.csv', index=False)\n",
    "submission_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ward_11                      0.0\n",
       "ward_136                     0.0\n",
       "ward_16                      0.0\n",
       "ward_17                      0.0\n",
       "ward_28                      0.0\n",
       "ward_30                      0.0\n",
       "ward_43                      0.0\n",
       "ward_615                     0.0\n",
       "ward_72                      0.0\n",
       "ward_Others                  1.0\n",
       "ward_nan                     0.0\n",
       "public_meeting_0             1.0\n",
       "public_meeting_1             0.0\n",
       "public_meeting_2             0.0\n",
       "public_meeting_nan           0.0\n",
       "scheme_management_0          1.0\n",
       "scheme_management_1          0.0\n",
       "scheme_management_10         0.0\n",
       "scheme_management_11         0.0\n",
       "scheme_management_12         0.0\n",
       "scheme_management_2          0.0\n",
       "scheme_management_3          0.0\n",
       "scheme_management_4          0.0\n",
       "scheme_management_5          0.0\n",
       "scheme_management_6          0.0\n",
       "scheme_management_7          0.0\n",
       "scheme_management_8          0.0\n",
       "scheme_management_9          0.0\n",
       "scheme_management_nan        0.0\n",
       "scheme_name_1                0.0\n",
       "                            ... \n",
       "extraction_type_group_3      0.0\n",
       "extraction_type_group_4      0.0\n",
       "extraction_type_group_5      0.0\n",
       "extraction_type_group_6      0.0\n",
       "extraction_type_group_7      0.0\n",
       "extraction_type_group_8      0.0\n",
       "extraction_type_group_9      0.0\n",
       "extraction_type_group_nan    0.0\n",
       "extraction_type_class_0      1.0\n",
       "extraction_type_class_1      0.0\n",
       "extraction_type_class_2      0.0\n",
       "extraction_type_class_3      0.0\n",
       "extraction_type_class_4      0.0\n",
       "extraction_type_class_5      0.0\n",
       "extraction_type_class_6      0.0\n",
       "extraction_type_class_nan    0.0\n",
       "management_0                 1.0\n",
       "management_1                 0.0\n",
       "management_10                0.0\n",
       "management_11                0.0\n",
       "management_2                 0.0\n",
       "management_3                 0.0\n",
       "management_4                 0.0\n",
       "management_5                 0.0\n",
       "management_6                 0.0\n",
       "management_7                 0.0\n",
       "management_8                 0.0\n",
       "management_9                 0.0\n",
       "management_nan               0.0\n",
       "management_group_0           1.0\n",
       "Name: 0, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.iloc[0][150:250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
