{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/train_cleaned_v0.5.csv')\n",
    "test = pd.read_csv('./Data/test_cleaned_v0.5.csv')\n",
    "\n",
    "labels = pd.read_csv('./Data/training_set_labels.csv')\n",
    "train = train.merge(labels, on=\"id\")\n",
    "target = train.pop(\"status_group\")\n",
    "\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "\n",
    "data = pd.concat([train,test])\n",
    "\n",
    "data['date_recorded'] = pd.to_datetime(data['date_recorded'])\n",
    "data['date_recorded'] = data['date_recorded'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded', 'latitude','longitude','amount_tsh', 'gps_height', 'population', 'operation_years', 'construction_year']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population_imp_random_choice', 'construction_year_imp_normal', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh_imp_random_choice', 'longitude_imp_normal',\n",
    "                 'longitude_imp_random_choice', 'latitude_imp_normal', 'latitude_imp_random_choice',\n",
    "                 'operation_years_imp_normal', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random sample from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_normal','longitude_imp_normal','amount_tsh_imp_normal',\n",
    "                'gps_height_imp_normal', 'population_imp_normal', 'operation_years_imp_normal',\n",
    "               'construction_year_imp_normal']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height', 'population',\n",
    "               'population_imp_random_choice', 'construction_year', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh', 'amount_tsh_imp_random_choice', 'longitude',\n",
    "                 'longitude_imp_random_choice', 'latitude', 'latitude_imp_random_choice',\n",
    "                 'operation_years', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random choice from empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_random_choice','longitude_imp_random_choice','amount_tsh_imp_random_choice',\n",
    "                'gps_height_imp_random_choice', 'population_imp_random_choice',\n",
    "                'operation_years_imp_random_choice', 'construction_year_imp_random_choice']\n",
    "\n",
    "data = data.drop(['gps_height', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population', 'construction_year_imp_normal', 'construction_year',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh', 'longitude_imp_normal',\n",
    "                 'longitude', 'latitude_imp_normal', 'latitude',\n",
    "                 'operation_years_imp_normal', 'operation_years'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[num_features])\n",
    "data[num_features] = scaler.transform(data[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical features for OneHotEncoding\n",
    "cat_features = list(data.columns)\n",
    "for feature in num_features:\n",
    "    cat_features.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove train and id column for OneHotEncoding\n",
    "cat_features.remove('train')\n",
    "cat_features.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert factorized categorical features to strings\n",
    "data[cat_features] = data[cat_features].applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding of categorical features\n",
    "data = pd.concat([data, pd.get_dummies(data[cat_features], dummy_na=True)], axis=1)\n",
    "data = data.drop(cat_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract training/test sets\n",
    "train_df = data[data[\"train\"] == 1]\n",
    "test_df = data[data[\"train\"] == 0]\n",
    "train_df.drop([\"train\"], axis=1, inplace=True)\n",
    "train_df.drop(['id'],axis=1, inplace=True)\n",
    "test_df.drop([\"train\"], axis=1, inplace=True)\n",
    "\n",
    "id_test = test_df['id']\n",
    "test_df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train model and predict values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "svm.fit(train_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = svm.predict(test_df)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions['id'] = id_test\n",
    "predictions.columns = ['status_group','id']\n",
    "predictions = predictions[['id','status_group']]\n",
    "# convert into submission format\n",
    "\n",
    "formatsub = pd.read_csv('./Data/submission_format.csv')\n",
    "submission_format = pd.merge(formatsub, predictions, on=['id'], how='inner')\n",
    "submission_format.drop(['status_group_x'],axis=1,inplace=True)\n",
    "submission_format.columns = ['id','status_group']\n",
    "\n",
    "submission_format.to_csv('./Results/submission_format_SVM_empirical.csv', index=False)\n",
    "submission_format.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
