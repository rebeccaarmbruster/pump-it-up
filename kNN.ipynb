{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./Data/train_cleaned_v0.0.csv')\n",
    "test = pd.read_csv('./Data/test_cleaned_v0.0.csv')\n",
    "train_raw = pd.read_csv('./Data/training_set_values.csv')\n",
    "test_raw = pd.read_csv('./Data/test_set_values.csv')\n",
    "\n",
    "labels = pd.read_csv('./Data/training_set_labels.csv')\n",
    "train = train.merge(labels, on=\"id\")\n",
    "target = train.pop(\"status_group\")\n",
    "\n",
    "train['train'] = 1\n",
    "test['train'] = 0\n",
    "\n",
    "data = pd.concat([train,test])\n",
    "\n",
    "data['date_recorded'] = pd.to_datetime(data['date_recorded'])\n",
    "data['date_recorded'] = data['date_recorded'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude','longitude','amount_tsh', 'gps_height', 'population', 'operation_years', 'construction_year']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population_imp_random_choice', 'construction_year_imp_normal', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh_imp_random_choice', 'longitude_imp_normal',\n",
    "                 'longitude_imp_random_choice', 'latitude_imp_normal', 'latitude_imp_random_choice',\n",
    "                 'operation_years_imp_normal', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random sample from normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_normal','longitude_imp_normal','amount_tsh_imp_normal',\n",
    "                'gps_height_imp_normal', 'population_imp_normal', 'operation_years_imp_normal',\n",
    "               'construction_year_imp_normal']\n",
    "\n",
    "data = data.drop(['gps_height_imp_random_choice', 'gps_height', 'population',\n",
    "               'population_imp_random_choice', 'construction_year', 'construction_year_imp_random_choice',\n",
    "               'amount_tsh', 'amount_tsh_imp_random_choice', 'longitude',\n",
    "                 'longitude_imp_random_choice', 'latitude', 'latitude_imp_random_choice',\n",
    "                 'operation_years', 'operation_years_imp_random_choice'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execute following cell to impute missing values with random sample from empirical distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = ['date_recorded','latitude_imp_random_choice','longitude_imp_random_choice','amount_tsh_imp_random_choice',\n",
    "                'gps_height_imp_random_choice', 'population_imp_random_choice',\n",
    "                'operation_years_imp_random_choice', 'construction_year_imp_random_choice']\n",
    "\n",
    "data = data.drop(['gps_height', 'gps_height_imp_normal', 'population_imp_normal',\n",
    "               'population', 'construction_year_imp_normal', 'construction_year',\n",
    "               'amount_tsh_imp_normal', 'amount_tsh', 'longitude_imp_normal',\n",
    "                 'longitude', 'latitude_imp_normal', 'latitude',\n",
    "                 'operation_years_imp_normal', 'operation_years'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(data[num_features])\n",
    "data[num_features] = scaler.transform(data[num_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get categorical features for OneHotEncoding\n",
    "cat_features = list(data.columns)\n",
    "for feature in num_features:\n",
    "    cat_features.remove(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove train and id column for OneHotEncoding\n",
    "cat_features.remove('train')\n",
    "cat_features.remove('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimension of some categorical features\n",
    "dim_red_features = 'funder installer scheme_name lga ward subvillage wpt_name'.split()\n",
    "for feature in dim_red_features:\n",
    "    train = train.assign(count = train.groupby(feature)[feature].transform('count')).sort_values(by = ['count',feature], ascending = [False,True])\n",
    "    top_values = train.drop_duplicates('count')\n",
    "    top_values = list(top_values.nlargest(10, 'count')[feature])\n",
    "    data[feature] = data[feature].apply(lambda x: x if (x in top_values) | (str(x) == 'nan') else 'Others')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert factorized categorical features to strings\n",
    "data[cat_features] = data[cat_features].applymap(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OneHotEncoding of categorical features\n",
    "data = pd.concat([data, pd.get_dummies(data[cat_features], dummy_na=True)], axis=1)\n",
    "data = data.drop(cat_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\py36\\lib\\site-packages\\pandas\\core\\frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "# extract training/test sets\n",
    "train_df = data[data[\"train\"] == 1]\n",
    "test_df = data[data[\"train\"] == 0]\n",
    "train_df.drop([\"train\"], axis=1, inplace=True)\n",
    "train_df.drop(['id'],axis=1, inplace=True)\n",
    "test_df.drop([\"train\"], axis=1, inplace=True)\n",
    "\n",
    "id_test = test_df['id']\n",
    "test_df.drop(['id'],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, n_jobs = -1)\n",
    "knn.fit(train_df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50785</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51630</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17168</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45559</td>\n",
       "      <td>non functional</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49871</td>\n",
       "      <td>functional</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id    status_group\n",
       "0  50785      functional\n",
       "1  51630      functional\n",
       "2  17168      functional\n",
       "3  45559  non functional\n",
       "4  49871      functional"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = knn.predict(test_df)\n",
    "\n",
    "predictions = pd.DataFrame(predictions)\n",
    "predictions['id'] = id_test\n",
    "predictions.columns = ['status_group','id']\n",
    "predictions = predictions[['id','status_group']]\n",
    "# convert into submission format\n",
    "\n",
    "formatsub = pd.read_csv('./Data/submission_format.csv')\n",
    "submission_format = pd.merge(formatsub, predictions, on=['id'], how='inner')\n",
    "submission_format.drop(['status_group_x'],axis=1,inplace=True)\n",
    "submission_format.columns = ['id','status_group']\n",
    "\n",
    "submission_format.to_csv('./Results/submission_format_kNN_median.csv', index=False)\n",
    "submission_format.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
